{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import models\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from config import cfg\n",
    "from data import fetch_dataset, make_data_loader, split_dataset, SplitDataset\n",
    "from utils import save, to_device, process_control, process_dataset, make_optimizer, make_scheduler, resume, collate\n",
    "\n",
    "from masking_functions import SNIP\n",
    "\n",
    "import train_classifier_fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_control()\n",
    "cfg['data_name'] = 'CIFAR10'\n",
    "cfg['model_name'] = 'conv'\n",
    "cfg[\"data_split_mode\"] ='non-iid-2'\n",
    "cfg[\"num_users\"] = 100\n",
    "\n",
    "seeds = list(range(cfg['init_seed'], cfg['init_seed'] + cfg['num_experiments']))\n",
    "model_tag_list = [str(seeds[0]), cfg['data_name'], cfg['subset'], cfg['model_name'], cfg['control_name']]\n",
    "cfg['model_tag'] = '_'.join([x for x in model_tag_list if x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "non-iid-2\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(cfg['device'])\n",
    "print(cfg[\"data_split_mode\"])\n",
    "print(cfg[\"num_users\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching data CIFAR10...\n",
      "data ready\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_dataset(cfg['data_name'], cfg['subset'])\n",
    "process_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "Size: 50000\n",
       "Root: ./data/CIFAR10\n",
       "Split: train\n",
       "Subset: label\n",
       "Transforms: Compose(\n",
       "    RandomCrop(size=(32, 32), padding=4)\n",
       "    RandomHorizontalFlip(p=0.5)\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval('models.{}(model_rate=cfg[\"global_model_rate\"], track=True).to(cfg[\"device\"]).to(cfg[\"device\"])'\n",
    "                 .format(cfg['model_name']))\n",
    "optimizer = make_optimizer(model, cfg['lr'])\n",
    "scheduler = make_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv(\n",
      "  (blocks): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Scaler()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): Scaler()\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): Scaler()\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): Scaler()\n",
      "    (17): BatchNorm2d(512, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): AdaptiveAvgPool2d(output_size=1)\n",
      "    (20): Flatten(start_dim=1, end_dim=-1)\n",
      "    (21): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_split is None:\n",
    "    data_split, label_split = split_dataset(dataset, cfg['num_users'], cfg['data_split_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "29626\n",
      "[7, 8]\n"
     ]
    }
   ],
   "source": [
    "print(len(data_split['train'][0]))\n",
    "print(data_split['train'][0][0])\n",
    "print(label_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = make_data_loader({'train': SplitDataset(dataset['train'], data_split['train'][0])})['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(77756, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "keep_mask = SNIP(model, 0.05, data_loader, cfg['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(keep_mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 1.],\n",
      "          [0., 0., 0.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 0., 1.]],\n",
      "\n",
      "         [[0., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [0., 0., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [0., 1., 1.],\n",
      "          [1., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [0., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "print(keep_mask[0].to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subnetfl",
   "language": "python",
   "name": "subnetfl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
