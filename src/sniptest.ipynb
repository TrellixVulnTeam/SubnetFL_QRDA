{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from config import cfg\n",
    "from data import fetch_dataset, make_data_loader, split_dataset, SplitDataset\n",
    "from utils import save, to_device, process_control, process_dataset, make_optimizer, make_scheduler, resume, collate\n",
    "from logger import Logger\n",
    "from metrics import Metric\n",
    "import time\n",
    "import datetime\n",
    "import shutil\n",
    "import copy\n",
    "\n",
    "from masking_functions import SNIP\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import train_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_control()\n",
    "cfg['data_name'] = 'CIFAR10'\n",
    "cfg['model_name'] = 'conv'\n",
    "cfg[\"data_split_mode\"] ='non-iid-2'\n",
    "cfg[\"num_users\"] = 100\n",
    "cfg[\"batch_size\"][\"train\"] = 128\n",
    "cfg[\"batch_size\"][\"test\"] = 128\n",
    "cfg[\"num_epochs\"] = 50\n",
    "cfg[\"prune_rate\"] = 0.05\n",
    "\n",
    "seeds = list(range(cfg['init_seed'], cfg['init_seed'] + cfg['num_experiments']))\n",
    "model_tag_list = [str(seeds[0]), cfg['data_name'], cfg['subset'], cfg['model_name'], cfg['control_name']]\n",
    "cfg['model_tag'] = '_'.join([x for x in model_tag_list if x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "non-iid-2\n",
      "100\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(cfg['device'])\n",
    "print(cfg[\"data_split_mode\"])\n",
    "print(cfg[\"num_users\"])\n",
    "print(cfg[\"batch_size\"][\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching data CIFAR10...\n",
      "data ready\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_dataset(cfg['data_name'], cfg['subset'])\n",
    "process_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "Size: 50000\n",
       "Root: ./data/CIFAR10\n",
       "Split: train\n",
       "Subset: label\n",
       "Transforms: Compose(\n",
       "    RandomCrop(size=(32, 32), padding=4)\n",
       "    RandomHorizontalFlip(p=0.5)\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval('models.{}(model_rate=cfg[\"global_model_rate\"], track=True).to(cfg[\"device\"]).to(cfg[\"device\"])'\n",
    "                 .format(cfg['model_name']))\n",
    "optimizer = make_optimizer(model, cfg['lr'])\n",
    "scheduler = make_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv(\n",
      "  (blocks): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Scaler()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): Scaler()\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): Scaler()\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): Scaler()\n",
      "    (17): BatchNorm2d(512, eps=1e-05, momentum=None, affine=True, track_running_stats=True)\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): AdaptiveAvgPool2d(output_size=1)\n",
      "    (20): Flatten(start_dim=1, end_dim=-1)\n",
      "    (21): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_split is None:\n",
    "    data_split, label_split = split_dataset(dataset, cfg['num_users'], cfg['data_split_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "14924\n",
      "[3, 7]\n"
     ]
    }
   ],
   "source": [
    "print(len(data_split['train'][0]))\n",
    "print(data_split['train'][0][0])\n",
    "print(label_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = make_data_loader({'train': SplitDataset(dataset['train'], data_split['train'][0])})['train']\n",
    "test_loader = make_data_loader({'test': SplitDataset(dataset['test'], data_split['test'][0])})['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "batch = collate(next(iter(data_loader)))\n",
    "print(len(batch['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(77756, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "keep_mask = SNIP(model, cfg[\"prune_rate\"], data_loader, cfg['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print((keep_mask[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_mask(mask):\n",
    "    flat_mask = []\n",
    "    for m in mask:\n",
    "        flat_mask.extend(m.flatten().to(torch.long).tolist())\n",
    "    return flat_mask\n",
    "\n",
    "def mask_similarity(mask1, mask2):\n",
    "    flat_mask1 = []\n",
    "    flat_mask2 = []\n",
    "    for m1, m2 in zip(mask1, mask2):\n",
    "        flat_mask1.extend(m1.flatten().to(torch.long).tolist())\n",
    "        flat_mask2.extend(m2.flatten().to(torch.long).tolist())\n",
    "    paramnum = len(flat_mask1)\n",
    "    masknum = int(sum(flat_mask1))\n",
    "    overlap_list = [p1 == p2 == 1 for p1, p2 in zip(flat_mask1, flat_mask2)]\n",
    "    overlap = int(sum(overlap_list))\n",
    "    return overlap / masknum\n",
    "\n",
    "def layer_similarity(mask1, mask2):\n",
    "    masknums = []\n",
    "    overlaps = []\n",
    "    for m1, m2 in zip(mask1, mask2):\n",
    "        fm1 = m1.flatten().to(torch.long).tolist()\n",
    "        fm2 = m2.flatten().to(torch.long).tolist()\n",
    "        masknums.append(sum(fm1))\n",
    "        overlaps.append(sum([p1 == p2 == 1 for p1, p2 in zip(fm1, fm2)]))\n",
    "        \n",
    "    return [o/p for o, p in zip(overlaps, masknums)]\n",
    "\n",
    "def print_similarity(a, b):\n",
    "    print(f\"the overlap between {client_label[a]}  and {client_label[b]} is {mask_similarity(client_masks[a], client_masks[b])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data = []\n",
    "client_label = label_split\n",
    "for m in range(cfg[\"num_users\"]):\n",
    "    client_data.append(make_data_loader({'train': SplitDataset(dataset['train'], data_split['train'][m])})['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77757, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77757, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n",
      "tensor(77756, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "client_masks = []\n",
    "for m in range(cfg[\"num_users\"]):\n",
    "    client_masks.append(SNIP(model, cfg[\"prune_rate\"], client_data[m], cfg['device']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7]\n",
      "[3, 4]\n",
      "[4, 6]\n",
      "[0, 3]\n",
      "[2, 6]\n",
      "[6, 8]\n",
      "[1, 7]\n",
      "[6, 8]\n",
      "[3, 6]\n",
      "[7]\n",
      "[0, 3]\n",
      "[2, 7]\n",
      "[5, 9]\n",
      "[2, 9]\n",
      "[3, 5]\n",
      "[1]\n",
      "[7, 9]\n",
      "[5, 8]\n",
      "[7, 9]\n",
      "[6, 9]\n",
      "[0, 7]\n",
      "[0]\n",
      "[1, 3]\n",
      "[1, 9]\n",
      "[5, 8]\n",
      "[2, 4]\n",
      "[0, 3]\n",
      "[1, 4]\n",
      "[0, 4]\n",
      "[4, 7]\n",
      "[0, 9]\n",
      "[0, 3]\n",
      "[3, 9]\n",
      "[1, 6]\n",
      "[6, 8]\n",
      "[1, 8]\n",
      "[4, 5]\n",
      "[3, 4]\n",
      "[1, 8]\n",
      "[7, 8]\n",
      "[3, 8]\n",
      "[0, 6]\n",
      "[5, 6]\n",
      "[0, 6]\n",
      "[4, 7]\n",
      "[3, 6]\n",
      "[5]\n",
      "[8]\n",
      "[0, 3]\n",
      "[5, 9]\n",
      "[0, 7]\n",
      "[2, 5]\n",
      "[4, 7]\n",
      "[4, 5]\n",
      "[1]\n",
      "[2, 9]\n",
      "[2, 8]\n",
      "[7, 8]\n",
      "[2, 3]\n",
      "[2, 6]\n",
      "[4, 5]\n",
      "[2, 7]\n",
      "[6, 8]\n",
      "[5]\n",
      "[4, 7]\n",
      "[3, 4]\n",
      "[1, 6]\n",
      "[2, 9]\n",
      "[2, 5]\n",
      "[6, 7]\n",
      "[5, 8]\n",
      "[0, 5]\n",
      "[7, 8]\n",
      "[0, 1]\n",
      "[9]\n",
      "[1, 8]\n",
      "[1, 3]\n",
      "[0, 2]\n",
      "[0, 6]\n",
      "[2, 7]\n",
      "[2, 6]\n",
      "[2, 5]\n",
      "[8, 9]\n",
      "[1, 3]\n",
      "[1, 8]\n",
      "[2, 6]\n",
      "[7, 9]\n",
      "[1, 2]\n",
      "[4]\n",
      "[1]\n",
      "[2, 9]\n",
      "[4]\n",
      "[0, 5]\n",
      "[9]\n",
      "[0, 3]\n",
      "[8, 9]\n",
      "[0, 4]\n",
      "[2, 3]\n",
      "[5, 9]\n",
      "[4, 6]\n"
     ]
    }
   ],
   "source": [
    "for l in client_label:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the overlap between [0, 3]  and [3, 7] is 0.32751170327691753\n",
      "the overlap between [0, 3]  and [3, 4] is 0.320296825968414\n",
      "the overlap between [0, 3]  and [4, 6] is 0.26966407737023507\n",
      "the overlap between [0, 3]  and [0, 3] is 1.0\n",
      "the overlap between [0, 3]  and [2, 6] is 0.35062246000308656\n",
      "the overlap between [0, 3]  and [6, 8] is 0.3525001286074387\n",
      "the overlap between [0, 3]  and [1, 7] is 0.33342764545501313\n",
      "the overlap between [0, 3]  and [6, 8] is 0.35320746952003707\n",
      "the overlap between [0, 3]  and [3, 6] is 0.34653274345388135\n",
      "the overlap between [0, 3]  and [7] is 0.28793919440300425\n",
      "the overlap between [0, 3]  and [0, 3] is 0.696370698081177\n",
      "the overlap between [0, 3]  and [2, 7] is 0.2932764031071557\n",
      "the overlap between [0, 3]  and [5, 9] is 0.34284170996450436\n",
      "the overlap between [0, 3]  and [2, 9] is 0.3291450177478265\n",
      "the overlap between [0, 3]  and [3, 5] is 0.35494366994186943\n",
      "the overlap between [0, 3]  and [1] is 0.2984850043726529\n",
      "the overlap between [0, 3]  and [7, 9] is 0.33850763928185607\n",
      "the overlap between [0, 3]  and [5, 8] is 0.351149750501569\n",
      "the overlap between [0, 3]  and [7, 9] is 0.33754308349194917\n",
      "the overlap between [0, 3]  and [6, 9] is 0.31453521271670354\n",
      "the overlap between [0, 3]  and [0, 7] is 0.40598796234374196\n",
      "the overlap between [0, 3]  and [0] is 0.31458665569216526\n",
      "the overlap between [0, 3]  and [1, 3] is 0.3557796182931221\n",
      "the overlap between [0, 3]  and [1, 9] is 0.3334147847111477\n",
      "the overlap between [0, 3]  and [5, 8] is 0.3517670662071094\n",
      "the overlap between [0, 3]  and [2, 4] is 0.306895930860641\n",
      "the overlap between [0, 3]  and [0, 3] is 0.6495061474355677\n",
      "the overlap between [0, 3]  and [1, 4] is 0.3034106692731108\n",
      "the overlap between [0, 3]  and [0, 4] is 0.40444467307989096\n",
      "the overlap between [0, 3]  and [4, 7] is 0.2999125469417151\n"
     ]
    }
   ],
   "source": [
    "tocompare = 3\n",
    "for i in range(30):\n",
    "    print_similarity(tocompare, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne print\n",
    "n_components = 2\n",
    "learning_rate = 500\n",
    "model = TSNE(n_components=n_components, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kjb/.conda/envs/subnetfl/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39040/899440507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "flat_masks = []\n",
    "for m in range(cfg['num_users']):\n",
    "    flat_masks.append(flatten_mask(client_masks[m]))\n",
    "embedded_masks = model.fit_transform(flat_masks)\n",
    "print(embedded_masks.shape)\n",
    "em = pd.DataFrame(embedded_masks, columns=[\"x\", \"y\"])\n",
    "em['labels'] = [str(l) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.scatterplot(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    data=em[:50],\n",
    "    hue=\"labels\",\n",
    "    s=40.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_prune_mask(net, keep_masks):\n",
    "\n",
    "    # Before I can zip() layers and pruning masks I need to make sure they match\n",
    "    # one-to-one by removing all the irrelevant modules:\n",
    "    prunable_layers = filter(\n",
    "        lambda layer: isinstance(layer, nn.Conv2d) or isinstance(\n",
    "            layer, nn.Linear), net.modules())\n",
    "\n",
    "    for layer, keep_mask in zip(prunable_layers, keep_masks):\n",
    "        assert (layer.weight.shape == keep_mask.shape)\n",
    "\n",
    "        def hook_factory(keep_mask):\n",
    "            \"\"\"\n",
    "            The hook function can't be defined directly here because of Python's\n",
    "            late binding which would result in all hooks getting the very last\n",
    "            mask! Getting it through another function forces early binding.\n",
    "            \"\"\"\n",
    "\n",
    "            def hook(grads):\n",
    "                return grads * keep_mask\n",
    "\n",
    "            return hook\n",
    "\n",
    "        # mask[i] == 0 --> Prune parameter\n",
    "        # mask[i] == 1 --> Keep parameter\n",
    "\n",
    "        # Step 1: Set the masked weights to zero (NB the biases are ignored)\n",
    "        # Step 2: Make sure their gradients remain zero\n",
    "        layer.weight.data[keep_mask == 0.] = 0.\n",
    "        layer.weight.register_hook(hook_factory(keep_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, optimizer, logger, epoch):\n",
    "    metric = Metric()\n",
    "    model.train(True)\n",
    "    start_time = time.time()\n",
    "    for i, input in enumerate(data_loader):\n",
    "        input = collate(input)\n",
    "        input_size = input['img'].size(0)\n",
    "        input = to_device(input, cfg['device'])\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        output['loss'] = output['loss'].mean() if cfg['world_size'] > 1 else output['loss']\n",
    "        output['loss'].backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        evaluation = metric.evaluate(cfg['metric_name']['train'], input, output)\n",
    "        logger.append(evaluation, 'train', n=input_size)\n",
    "        if i % int((len(data_loader) * cfg['log_interval']) + 1) == 0:\n",
    "            batch_time = (time.time() - start_time) / (i + 1)\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            epoch_finished_time = datetime.timedelta(seconds=round(batch_time * (len(data_loader) - i - 1)))\n",
    "            exp_finished_time = epoch_finished_time + datetime.timedelta(\n",
    "                seconds=round((cfg['num_epochs'] - epoch) * batch_time * len(data_loader)))\n",
    "            info = {'info': ['Model: {}'.format(cfg['model_tag']),\n",
    "                             'Train Epoch: {}({:.0f}%)'.format(epoch, 100. * i / len(data_loader)),\n",
    "                             'Learning rate: {}'.format(lr), 'Epoch Finished Time: {}'.format(epoch_finished_time),\n",
    "                             'Experiment Finished Time: {}'.format(exp_finished_time)]}\n",
    "            logger.append(info, 'train', mean=False)\n",
    "            logger.write('train', cfg['metric_name']['train'])\n",
    "    return\n",
    "def stats(data_loader, model):\n",
    "    with torch.no_grad():\n",
    "        test_model = eval('models.{}(model_rate=cfg[\"global_model_rate\"], track=True).to(cfg[\"device\"])'\n",
    "                          .format(cfg['model_name']))\n",
    "        test_model.load_state_dict(model.state_dict(), strict=False)\n",
    "        test_model.train(True)\n",
    "        for i, input in enumerate(data_loader):\n",
    "            input = collate(input)\n",
    "            input = to_device(input, cfg['device'])\n",
    "            test_model(input)\n",
    "    return test_model\n",
    "\n",
    "def test(data_loader, model, logger, epoch):\n",
    "    with torch.no_grad():\n",
    "        metric = Metric()\n",
    "        model.train(False)\n",
    "        for i, input in enumerate(data_loader):\n",
    "            input = collate(input)\n",
    "            input_size = input['img'].size(0)\n",
    "            input = to_device(input, cfg['device'])\n",
    "            output = model(input)\n",
    "            output['loss'] = output['loss'].mean() if cfg['world_size'] > 1 else output['loss']\n",
    "            evaluation = metric.evaluate(cfg['metric_name']['test'], input, output)\n",
    "            logger.append(evaluation, 'test', input_size)\n",
    "        info = {'info': ['Model: {}'.format(cfg['model_tag']), 'Test Epoch: {}({:.0f}%)'.format(epoch, 100.)]}\n",
    "        logger.append(info, 'test', mean=False)\n",
    "        logger.write('test', cfg['metric_name']['test'])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 1(0%)  Loss: 2.4564  Accuracy: 0.0000  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:14\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 1(50%)  Loss: 1.9602  Accuracy: 39.8438  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:12\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 1(100%)  Loss: 0.7750  Accuracy: 65.0000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 2(0%)  Loss: 1.5119  Accuracy: 49.5223  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:10\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 2(50%)  Loss: 1.2631  Accuracy: 53.9593  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:13\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 2(100%)  Loss: 0.6599  Accuracy: 70.0000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 3(0%)  Loss: 1.1073  Accuracy: 58.2447  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:11\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 3(50%)  Loss: 0.9971  Accuracy: 61.3439  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:12\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 3(100%)  Loss: 0.6174  Accuracy: 71.0000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 4(0%)  Loss: 0.9148  Accuracy: 63.7592  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 4(50%)  Loss: 0.8596  Accuracy: 65.7113  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:10\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 4(100%)  Loss: 0.6193  Accuracy: 71.7500\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 5(0%)  Loss: 0.8213  Accuracy: 66.6353  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:10\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 5(50%)  Loss: 0.7781  Accuracy: 68.2886  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:12\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 5(100%)  Loss: 0.6936  Accuracy: 71.4000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 6(0%)  Loss: 0.7417  Accuracy: 69.8250  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 6(50%)  Loss: 0.7168  Accuracy: 70.6311  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:11\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 6(100%)  Loss: 0.6896  Accuracy: 72.3333\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 7(0%)  Loss: 0.6953  Accuracy: 71.4194  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 7(50%)  Loss: 0.6752  Accuracy: 72.0745  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:10\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 7(100%)  Loss: 0.9297  Accuracy: 70.5714\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 8(0%)  Loss: 0.6556  Accuracy: 72.7674  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 8(50%)  Loss: 0.6397  Accuracy: 73.3007  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:11\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 8(100%)  Loss: 0.8899  Accuracy: 71.2500\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 9(0%)  Loss: 0.6308  Accuracy: 73.6676  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 9(50%)  Loss: 0.6157  Accuracy: 74.2701  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:10\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 9(100%)  Loss: 0.9665  Accuracy: 70.2222\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 10(0%)  Loss: 0.6039  Accuracy: 74.7407  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:08\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 10(50%)  Loss: 0.5902  Accuracy: 75.2662  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:08\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 10(100%)  Loss: 0.9202  Accuracy: 71.2000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 11(0%)  Loss: 0.5810  Accuracy: 75.5460  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:08\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 11(50%)  Loss: 0.5706  Accuracy: 75.8544  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:10\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 11(100%)  Loss: 0.9927  Accuracy: 70.4545\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 12(0%)  Loss: 0.5605  Accuracy: 76.3326  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:11\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 12(50%)  Loss: 0.5491  Accuracy: 76.8185  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:11\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 12(100%)  Loss: 1.0524  Accuracy: 69.7500\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 13(0%)  Loss: 0.5421  Accuracy: 77.0235  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:08\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 13(50%)  Loss: 0.5325  Accuracy: 77.4593  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 13(100%)  Loss: 1.1863  Accuracy: 68.9231\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 14(0%)  Loss: 0.5249  Accuracy: 77.7308  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:08\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 14(50%)  Loss: 0.5186  Accuracy: 78.0506  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 14(100%)  Loss: 1.1734  Accuracy: 69.6429\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 15(0%)  Loss: 0.5108  Accuracy: 78.4091  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:10\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 15(50%)  Loss: 0.5048  Accuracy: 78.6566  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 15(100%)  Loss: 1.1898  Accuracy: 69.2667\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 16(0%)  Loss: 0.4977  Accuracy: 78.9460  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:10\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 16(50%)  Loss: 0.4975  Accuracy: 78.9193  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 16(100%)  Loss: 1.1677  Accuracy: 70.0000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 17(0%)  Loss: 0.4912  Accuracy: 79.2446  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:09\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 17(50%)  Loss: 0.4862  Accuracy: 79.4012  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 17(100%)  Loss: 1.2864  Accuracy: 69.6471\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 18(0%)  Loss: 0.4820  Accuracy: 79.5665  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:08\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 18(50%)  Loss: 0.4783  Accuracy: 79.6601  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:06\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 18(100%)  Loss: 1.2664  Accuracy: 70.0556\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 19(0%)  Loss: 0.4734  Accuracy: 79.7875  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 19(50%)  Loss: 0.4683  Accuracy: 80.0192  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:06\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 19(100%)  Loss: 1.3372  Accuracy: 69.7895\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 20(0%)  Loss: 0.4633  Accuracy: 80.2451  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:07\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 20(50%)  Loss: 0.4611  Accuracy: 80.3217  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:06\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 20(100%)  Loss: 1.3490  Accuracy: 70.0000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 21(0%)  Loss: 0.4567  Accuracy: 80.4700  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 21(50%)  Loss: 0.4508  Accuracy: 80.7300  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:06\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 21(100%)  Loss: 1.3835  Accuracy: 69.8095\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 22(0%)  Loss: 0.4470  Accuracy: 80.8901  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 22(50%)  Loss: 0.4443  Accuracy: 80.9996  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 22(100%)  Loss: 1.3550  Accuracy: 70.3182\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 23(0%)  Loss: 0.4399  Accuracy: 81.1646  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 23(50%)  Loss: 0.4363  Accuracy: 81.3334  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 23(100%)  Loss: 1.3981  Accuracy: 70.3913\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 24(0%)  Loss: 0.4325  Accuracy: 81.5101  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 24(50%)  Loss: 0.4301  Accuracy: 81.6223  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 24(100%)  Loss: 1.3946  Accuracy: 70.6250\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 25(0%)  Loss: 0.4277  Accuracy: 81.7365  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 25(50%)  Loss: 0.4247  Accuracy: 81.8314  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 25(100%)  Loss: 1.3633  Accuracy: 71.1600\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 26(0%)  Loss: 0.4226  Accuracy: 81.9370  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 26(50%)  Loss: 0.4196  Accuracy: 82.1018  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 26(100%)  Loss: 1.3397  Accuracy: 71.6154\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 27(0%)  Loss: 0.4203  Accuracy: 82.1222  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 27(50%)  Loss: 0.4169  Accuracy: 82.2848  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 27(100%)  Loss: 1.3278  Accuracy: 71.7037\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 28(0%)  Loss: 0.4142  Accuracy: 82.4332  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 28(50%)  Loss: 0.4106  Accuracy: 82.5627  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 28(100%)  Loss: 1.3098  Accuracy: 71.7857\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 29(0%)  Loss: 0.4074  Accuracy: 82.7223  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 29(50%)  Loss: 0.4043  Accuracy: 82.8629  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:05\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 29(100%)  Loss: 1.3226  Accuracy: 71.8276\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 30(0%)  Loss: 0.4009  Accuracy: 83.0189  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 30(50%)  Loss: 0.3976  Accuracy: 83.1698  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 30(100%)  Loss: 1.3236  Accuracy: 71.8000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 31(0%)  Loss: 0.3961  Accuracy: 83.2298  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 31(50%)  Loss: 0.3943  Accuracy: 83.3203  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 31(100%)  Loss: 1.3270  Accuracy: 71.8710\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 32(0%)  Loss: 0.3917  Accuracy: 83.4208  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 32(50%)  Loss: 0.3890  Accuracy: 83.5621  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 32(100%)  Loss: 1.3077  Accuracy: 72.1250\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 33(0%)  Loss: 0.3858  Accuracy: 83.6930  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 33(50%)  Loss: 0.3834  Accuracy: 83.7952  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 33(100%)  Loss: 1.2856  Accuracy: 72.4545\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 34(0%)  Loss: 0.3803  Accuracy: 83.9367  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 34(50%)  Loss: 0.3773  Accuracy: 84.0796  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 34(100%)  Loss: 1.2670  Accuracy: 72.6765\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 35(0%)  Loss: 0.3757  Accuracy: 84.1429  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 35(50%)  Loss: 0.3728  Accuracy: 84.2556  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 35(100%)  Loss: 1.2498  Accuracy: 73.0286\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 36(0%)  Loss: 0.3709  Accuracy: 84.3317  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 36(50%)  Loss: 0.3689  Accuracy: 84.3939  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:04\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 36(100%)  Loss: 1.2333  Accuracy: 73.0556\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 37(0%)  Loss: 0.3670  Accuracy: 84.4550  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 37(50%)  Loss: 0.3648  Accuracy: 84.5355  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:03\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 37(100%)  Loss: 1.2282  Accuracy: 73.2432\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 38(0%)  Loss: 0.3620  Accuracy: 84.6790  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 38(50%)  Loss: 0.3590  Accuracy: 84.8072  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 38(100%)  Loss: 1.2104  Accuracy: 73.5263\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 39(0%)  Loss: 0.3568  Accuracy: 84.9069  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 39(50%)  Loss: 0.3544  Accuracy: 85.0134  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 39(100%)  Loss: 1.1999  Accuracy: 73.8205\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 40(0%)  Loss: 0.3521  Accuracy: 85.1233  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 40(50%)  Loss: 0.3499  Accuracy: 85.2344  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 40(100%)  Loss: 1.1952  Accuracy: 73.8750\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 41(0%)  Loss: 0.3477  Accuracy: 85.3438  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 41(50%)  Loss: 0.3455  Accuracy: 85.4199  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 41(100%)  Loss: 1.1922  Accuracy: 73.9024\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 42(0%)  Loss: 0.3431  Accuracy: 85.5197  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 42(50%)  Loss: 0.3411  Accuracy: 85.6062  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:02\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 42(100%)  Loss: 1.1977  Accuracy: 73.9762\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 43(0%)  Loss: 0.3388  Accuracy: 85.7062  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 43(50%)  Loss: 0.3361  Accuracy: 85.8259  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 43(100%)  Loss: 1.1924  Accuracy: 74.0233\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 44(0%)  Loss: 0.3338  Accuracy: 85.9257  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 44(50%)  Loss: 0.3322  Accuracy: 85.9989  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 44(100%)  Loss: 1.1873  Accuracy: 74.1818\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 45(0%)  Loss: 0.3301  Accuracy: 86.0945  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 45(50%)  Loss: 0.3288  Accuracy: 86.1687  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 45(100%)  Loss: 1.1740  Accuracy: 74.3556\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 46(0%)  Loss: 0.3267  Accuracy: 86.2692  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 46(50%)  Loss: 0.3247  Accuracy: 86.3616  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 46(100%)  Loss: 1.1655  Accuracy: 74.5000\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 47(0%)  Loss: 0.3234  Accuracy: 86.4191  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 47(50%)  Loss: 0.3211  Accuracy: 86.5164  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:01\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 47(100%)  Loss: 1.1540  Accuracy: 74.7234\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 48(0%)  Loss: 0.3194  Accuracy: 86.5922  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:00\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 48(50%)  Loss: 0.3170  Accuracy: 86.6982  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:00\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 48(100%)  Loss: 1.1477  Accuracy: 74.7708\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 49(0%)  Loss: 0.3154  Accuracy: 86.7664  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:00\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 49(50%)  Loss: 0.3133  Accuracy: 86.8356  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:00\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 49(100%)  Loss: 1.1350  Accuracy: 74.9184\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 50(0%)  Loss: 0.3110  Accuracy: 86.9255  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:00\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Train Epoch: 50(50%)  Loss: 0.3088  Accuracy: 87.0358  Learning rate: 0.1  Epoch Finished Time: 0:00:00  Experiment Finished Time: 0:00:00\n",
      "Model: 0_CIFAR10_label_conv_1_100_0.1_iid_fix_a1_bn_1_1  Test Epoch: 50(100%)  Loss: 1.1187  Accuracy: 75.1400\n"
     ]
    }
   ],
   "source": [
    "model_copy = copy.deepcopy(model)\n",
    "optimizer = make_optimizer(model_copy, cfg['lr'])\n",
    "scheduler = make_scheduler(optimizer)\n",
    "apply_prune_mask(model_copy, keep_mask)\n",
    "last_epoch = 1\n",
    "logger_path = os.path.join('output', 'runs', 'train_{}'.format(cfg['model_tag']))\n",
    "logger = Logger(logger_path)\n",
    "for epoch in range(last_epoch, cfg['num_epochs'] + 1):\n",
    "        logger.safe(True)\n",
    "        train(data_loader, model_copy, optimizer, logger, epoch)\n",
    "        test_model = stats(data_loader, model_copy)\n",
    "        test(test_loader, test_model, logger, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subnetfl",
   "language": "python",
   "name": "subnetfl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
